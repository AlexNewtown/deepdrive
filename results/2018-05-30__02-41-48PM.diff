diff --git a/agents/dagger/agent.py b/agents/dagger/agent.py
index 5bf0490..b0fb9c1 100644
--- a/agents/dagger/agent.py
+++ b/agents/dagger/agent.py
@@ -242,8 +242,7 @@ class Agent(object):
             if self.net_name == net.MOBILENET_V2_NAME:
                 self.net = MobileNetV2(is_training=False)
             else:
-                with tf.variable_scope("model"):
-                    self.net = AlexNet(is_training=False)
+                self.net = AlexNet(is_training=False)
             saver = tf.train.Saver()
             saver.restore(self.sess, net_path)
 
diff --git a/agents/dagger/net.py b/agents/dagger/net.py
index 925bad3..6abf85c 100644
--- a/agents/dagger/net.py
+++ b/agents/dagger/net.py
@@ -164,20 +164,21 @@ class AlexNet(Net):
         self.starter_learning_rate = 2e-6
         super(AlexNet, self).__init__(*args, **kwargs)
 
-        # Decrease this to fit in your GPU's memory
-        # If you increase, remember that it decreases accuracy https://arxiv.org/abs/1711.00489
-        self.batch_size = 32
+        if self.is_training:
+            # Decrease this to fit in your GPU's memory
+            # If you increase, remember that it decreases accuracy https://arxiv.org/abs/1711.00489
+            self.batch_size = 32
 
-        # TODO: add polyak averaging.
-        self.learning_rate = tf.train.exponential_decay(self.starter_learning_rate, global_step=self.global_step,
-                                                        decay_steps=73000, decay_rate=0.5, staircase=True)
+            # TODO: add polyak averaging.
+            self.learning_rate = tf.train.exponential_decay(self.starter_learning_rate, global_step=self.global_step,
+                                                            decay_steps=73000, decay_rate=0.5, staircase=True)
 
-        if self.overfit:
-            self.weight_decay = 0.
-        else:
-            self.weight_decay = 0.0005
+            if self.overfit:
+                self.weight_decay = 0.
+            else:
+                self.weight_decay = 0.0005
 
-        self.mute_spurious_targets = False  # TODO: Try turning this on
+            self.mute_spurious_targets = False
 
     def _init_net(self):
         in_tensor = tf.placeholder(tf.float32, (None,) + self.input_image_shape)
diff --git a/gym_deepdrive/envs/deepdrive_gym_env.py b/gym_deepdrive/envs/deepdrive_gym_env.py
index 3a32989..b9c833a 100644
--- a/gym_deepdrive/envs/deepdrive_gym_env.py
+++ b/gym_deepdrive/envs/deepdrive_gym_env.py
@@ -4,6 +4,7 @@ import deepdrive_client
 import deepdrive_capture
 import os
 import random
+import sys
 import time
 from collections import deque, OrderedDict
 from multiprocessing import Process, Queue
@@ -39,6 +40,7 @@ class Score(object):
     total = 0
     gforce_penalty = 0
     lane_deviation_penalty = 0
+    time_penalty = 0
     progress_reward = 0
     got_stuck = False
 
@@ -379,9 +381,10 @@ class DeepDriveEnv(gym.Env):
             else:
                 step_time = None
             now = time.time()
-            time_penalty = now - self.score.start_time - self.score.episode_time
-            # self.score.time_penalty ++
-            self.score.episode_time = now - self.score.start_time
+            new_episode_time = now - self.score.start_time
+            time_penalty = new_episode_time - self.score.episode_time  # Time elapsed since last get reward
+            self.score.time_penalty += time_penalty
+            self.score.episode_time = new_episode_time
             if self.score.episode_time < 2.5:
                 # Give time to get on track after spawn
                 reward = 0
@@ -490,6 +493,7 @@ class DeepDriveEnv(gym.Env):
         log.info('benchmark lap #%d score: %f - average: %f', len(self.trial_scores), self.score.total, average)
         file_prefix = self.experiment + '_' if self.experiment else ''
         filename = os.path.join(c.BENCHMARK_DIR, '%s%s.csv' % (file_prefix, c.DATE_STR))
+        diff_filename = os.path.join(c.BENCHMARK_DIR, '%s%s.diff' % (file_prefix, c.DATE_STR))
         with open(filename, 'w', newline='') as csv_file:
             writer = csv.writer(csv_file)
             for i, score in enumerate(self.trial_scores):
@@ -498,7 +502,7 @@ class DeepDriveEnv(gym.Env):
                                      'gforce penalty', 'time penalty', 'got stuck', 'start', 'end', 'lap time'])
                 writer.writerow([i + 1, score.total,
                                  score.progress_reward, score.lane_deviation_penalty,
-                                 score.gforce_penalty, score.got_stuck, str(arrow.get(score.start_time).to('local')),
+                                 score.gforce_penalty, score.time_penalty, score.got_stuck, str(arrow.get(score.start_time).to('local')),
                                  str(arrow.get(score.end_time).to('local')),
                                  score.episode_time])
             writer.writerow([])
@@ -507,6 +511,14 @@ class DeepDriveEnv(gym.Env):
             writer.writerow(['std', std])
             writer.writerow(['high score', high])
             writer.writerow(['low score', low])
+            writer.writerow(['env', self.spec.id])
+            writer.writerow(['command', sys.argv])
+            writer.writerow(['commit', utils.run_command('git rev-parse --short HEAD')[0]])
+            writer.writerow(['diff file', diff_filename])
+            writer.writerow(['experiment', self.experiment or 'n/a'])
+
+        with open(diff_filename, 'w') as diff_file:
+            diff_file.write(utils.run_command('git diff')[0])
 
         log.info('median score %r', median)
         log.info('avg score %r', average)
@@ -515,6 +527,7 @@ class DeepDriveEnv(gym.Env):
         log.info('low score %r', low)
         log.info('progress_reward %r', self.score.progress_reward)
         log.info('lane_deviation_penalty %r', self.score.lane_deviation_penalty)
+        log.info('time_penalty %r', self.score.time_penalty)
         log.info('gforce_penalty %r', self.score.gforce_penalty)
         log.info('episode_time %r', self.score.episode_time)
         log.info('wrote results to %s', os.path.normpath(filename))